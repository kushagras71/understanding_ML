{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pipelines</b><br>\n",
    "<b>SVD</b>: Support Vector Decomposition.<br>\n",
    "<b>SVM</b>: Support Vector Machine.<br>\n",
    "Here is sample code for making a pipeline for multiclass data with SVD and SVM Classifier. The Code dosen't run since do data was fed to it. This is only for understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return metrics.cohen_kappa_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    weights=\"quadratic\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    # we dont need ID columns\n",
    "    idx = test.id.values.astype(int)\n",
    "    train = train.drop('id', axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "    # create labels. drop useless columns\n",
    "    y = train.relevance.values\n",
    "    # do some lambda magic on text columns\n",
    "    traindata = list(\n",
    "        train.apply(lambda x:'%s %s' % (x['text1'], x['text2']),axis=1)\n",
    "    )\n",
    "    testdata = list(\n",
    "        test.apply(lambda x:'%s %s' % (x['text1'], x['text2']),axis=1)\n",
    "    )\n",
    "    # tfidf vectorizer\n",
    "    tfv = TfidfVectorizer(\n",
    "        min_df=3,\n",
    "        max_features=None,\n",
    "        strip_accents='unicode',\n",
    "        analyzer='word',\n",
    "        token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 3),\n",
    "        use_idf=1,\n",
    "        smooth_idf=1,\n",
    "        sublinear_tf=1,\n",
    "        stop_words='english'\n",
    "    )\n",
    "    # Fit TFIDF\n",
    "    tfv.fit(traindata)\n",
    "    X = tfv.transform(traindata)\n",
    "    X_test = tfv.transform(testdata)\n",
    "    # Initialize SVD\n",
    "    svd = TruncatedSVD()\n",
    "    # Initialize the standard scaler\n",
    "    scl = StandardScaler()\n",
    "    # We will use SVM here..\n",
    "    svm_model = SVC()\n",
    "    # Create the pipeline\n",
    "    clf = pipeline.Pipeline(\n",
    "        [\n",
    "            ('svd', svd),\n",
    "            ('scl', scl),\n",
    "            ('svm', svm_model)\n",
    "        ]\n",
    "    )\n",
    "    # Create a parameter grid to search for\n",
    "    # best parameters for everything in the pipeline\n",
    "    param_grid = {\n",
    "        'svd__n_components' : [200, 300],\n",
    "        'svm__C': [10, 12]\n",
    "    }\n",
    "    # Kappa Scorer\n",
    "    kappa_scorer = metrics.make_scorer(\n",
    "        quadratic_weighted_kappa,\n",
    "        greater_is_better=True\n",
    "    )\n",
    "    # Initialize Grid Search Model\n",
    "    model = model_selection.GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=kappa_scorer,\n",
    "        verbose=10,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        cv=5\n",
    "    )\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(X, y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = model.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    # Get best model\n",
    "    best_model = model.best_estimator_\n",
    "    # Fit model with best parameters optimized for QWK\n",
    "    best_model.fit(X, y)\n",
    "    preds = best_model.predict(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

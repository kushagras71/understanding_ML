{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data,catcols):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2),50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values + 1,embed_dim, name=c)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim,))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300,activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300,activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/3\n",
      "480000/480000 [==============================] - 41s 85us/sample - loss: 0.4815 - val_loss: 0.4396\n",
      "Epoch 2/3\n",
      "480000/480000 [==============================] - 26s 54us/sample - loss: 0.4100 - val_loss: 0.3996\n",
      "Epoch 3/3\n",
      "480000/480000 [==============================] - 23s 47us/sample - loss: 0.4033 - val_loss: 0.4002\n",
      "0.7833288005375232\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/3\n",
      "480000/480000 [==============================] - 35s 72us/sample - loss: 0.4797 - val_loss: 0.4189\n",
      "Epoch 2/3\n",
      "480000/480000 [==============================] - 21s 44us/sample - loss: 0.4102 - val_loss: 0.3968\n",
      "Epoch 3/3\n",
      "480000/480000 [==============================] - 21s 44us/sample - loss: 0.4037 - val_loss: 0.3969\n",
      "0.7873778084490001\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/3\n",
      "480000/480000 [==============================] - 27s 56us/sample - loss: 0.4827 - val_loss: 0.4211\n",
      "Epoch 2/3\n",
      "480000/480000 [==============================] - 21s 45us/sample - loss: 0.4108 - val_loss: 0.3993\n",
      "Epoch 3/3\n",
      "480000/480000 [==============================] - 21s 44us/sample - loss: 0.4036 - val_loss: 0.3995\n",
      "0.7836379788722798\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/3\n",
      "480000/480000 [==============================] - 28s 57us/sample - loss: 0.4797 - val_loss: 0.4225\n",
      "Epoch 2/3\n",
      "480000/480000 [==============================] - 21s 43us/sample - loss: 0.4102 - val_loss: 0.4007\n",
      "Epoch 3/3\n",
      "480000/480000 [==============================] - 21s 44us/sample - loss: 0.4033 - val_loss: 0.3995\n",
      "0.7834545705744385\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/3\n",
      "480000/480000 [==============================] - 29s 60us/sample - loss: 0.4842 - val_loss: 0.4250\n",
      "Epoch 2/3\n",
      "480000/480000 [==============================] - 21s 45us/sample - loss: 0.4106 - val_loss: 0.3992\n",
      "Epoch 3/3\n",
      "480000/480000 [==============================] - 20s 41us/sample - loss: 0.4039 - val_loss: 0.3985\n",
      "0.7863427558021093\n"
     ]
    }
   ],
   "source": [
    "def run(fold):\n",
    "    df = pd.read_csv(\"input/cat_train_folds.csv\")\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"id\",\"target\",\"kfold\")\n",
    "    ]\n",
    "    \n",
    "    for col in features:\n",
    "        df.loc[:,col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    \n",
    "    for feat in features:\n",
    "        lbl_enc = preprocessing.LabelEncoder()\n",
    "        df.loc[:,feat] = lbl_enc.fit_transform(df[feat].values)\n",
    "        \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    model = create_model(df,features)\n",
    "    \n",
    "    xtrain = [\n",
    "        df_train[features].values[:,k] for k in range(len(features))\n",
    "    ]\n",
    "    \n",
    "    xvalid = [\n",
    "        df_valid[features].values[:,k] for k in range(len(features))\n",
    "    ]\n",
    "    \n",
    "    ytrain = df_train.target.values\n",
    "    yvalid = df_valid.target.values\n",
    "    \n",
    "    ytrain_cat = utils.to_categorical(ytrain)\n",
    "    yvalid_cat = utils.to_categorical(yvalid)\n",
    "    \n",
    "    model.fit(xtrain,\n",
    "             ytrain_cat,\n",
    "             validation_data=(xvalid,yvalid_cat),\n",
    "              verbose = 1,\n",
    "              batch_size = 1024,\n",
    "              epochs = 3,\n",
    "             )\n",
    "    valid_preds = model.predict(xvalid)[:,1]\n",
    "    print(metrics.roc_auc_score(yvalid,valid_preds))\n",
    "    K.clear_session()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run(0)\n",
    "    run(1)\n",
    "    run(2)\n",
    "    run(3)\n",
    "    run(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
